{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import  HuggingFaceInstructEmbeddings,HuggingFaceHubEmbeddings,HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "class Create_embeddings_from_pdf_files:\n",
    "    HFIembeddings=None\n",
    "    def __init__(self) -> None:\n",
    "        DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        if Create_embeddings_from_pdf_files.HFIembeddings is None:\n",
    "            Create_embeddings_from_pdf_files.HFIembeddings = HuggingFaceInstructEmbeddings(model_name=\"thenlper/gte-small\",cache_folder=\"./Models/\", model_kwargs={\"device\": DEVICE})\n",
    "            \n",
    "    def split_docs(self,pdf_file_path,chunk_size=1000,chunk_overlap=20):\n",
    "        docs = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap).split_documents(PyPDFLoader(pdf_file_path).load_and_split())\n",
    "        return docs\n",
    "    \n",
    "    def create_vectores_and_store_locally(self,vector_store_folder_name:str,folder_path:str):\n",
    "        current_vector_files=[file_name.split(\".\")[0] for file_name in os.listdir(vector_store_folder_name) if file_name.endswith(\".faiss\")]\n",
    "        for file in [os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path) if file_name.endswith(\".pdf\")]: \n",
    "            if os.path.basename(file).split(\".\")[0] not in current_vector_files:\n",
    "                FAISS.from_documents(self.split_docs(file),embedding=Create_embeddings_from_pdf_files.HFIembeddings).save_local(vector_store_folder_name,os.path.basename(file).split(\".\")[0])\n",
    "                print(\"vectore file created for: \",file)\n",
    "            else:\n",
    "                print(\"vectore file already exist for \",file)\n",
    "                \n",
    "    def load_vectore_stores(self,folder_path:str,current_vector_store:FAISS=None):\n",
    "        flag = current_vector_store is not None\n",
    "        for index in [os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path) if file_name.endswith(\".faiss\")]: \n",
    "            if flag:\n",
    "                current_vector_store.merge_from(FAISS.load_local(\"FAISS_db\",Create_embeddings_from_pdf_files.HFIembeddings,os.path.basename(index).split(\".\")[0]))\n",
    "            else:\n",
    "                flag = True\n",
    "                current_vector_store = FAISS.load_local(\"FAISS_db\",Create_embeddings_from_pdf_files.HFIembeddings,os.path.basename(index).split(\".\")[0])\n",
    "        return current_vector_store\n",
    "                \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Files\\LLM\\Project\\venv\\lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "vectore file already exist for  ./DataSourceFiles\\IPC_186045.pdf\n",
      "vectore file already exist for  ./DataSourceFiles\\special_marriage_act.pdf\n",
      "vectore file already exist for  ./DataSourceFiles\\THE_CODE_OF_CIVIL_PROCEDURE_1908.pdf\n"
     ]
    }
   ],
   "source": [
    "vector_db=Create_embeddings_from_pdf_files()\n",
    "vector_db.create_vectores_and_store_locally(\"FAISS_db\",\"./DataSourceFiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = vector_db.load_vectore_stores(\"FAISS_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.vectorstores import Chroma\n",
    "# # from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "# # from langchain.embeddings import  HuggingFaceInstructEmbeddings,HuggingFaceHubEmbeddings,HuggingFaceEmbeddings\n",
    "\n",
    "# from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# # model = SentenceTransformer(model_name_or_path=\"sentence-transformers/all-MiniLM-L6-v2\",cache_folder=\"./Models/\")\n",
    "# sentence_transformer_ef = SentenceTransformerEmbeddingFunction(model_name=\"D:\\Files\\LLM\\Project\\Models\\sentence-transformers_all-MiniLM-L6-v2\")\n",
    "# # # HFIembeddings = HuggingFaceHubEmbeddings(repo_id=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# # # # embedding_function = SentenceTransformerEmbeddings(model_name=\"gte-small\") #,cache_folder=\"./Models/\")\n",
    "# # print((sentence_transformer_ef))\n",
    "# vectorstore = Chroma.from_documents(documents=pages,embedding=sentence_transformer_ef,collection_name=\"law_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class QA_on_vctors_of_pdf:\n",
    "    \n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"\n",
    "    - You're a helpful AI assistant assigned to assist individuals seeking legal advice within the framework of Indian laws and the constitution.\n",
    "    - Your role is to guide users through legal processes and provide information in a lawful manner.\n",
    "    - Use the given text to answer the question in atleast 1000 words, give all accurate information.\n",
    "    - Answer questions step by step, highlighting relevant sections of Indian laws and the constitution, use bulleting to display more pretty and readable answer.\n",
    "    - Refrain from responding to queries that may not contribute to legal affairs, and provide accurate and relevant information without distortion.\n",
    "    - deny to give answers if its not available into provided text.\n",
    "{context}\n",
    "\n",
    "Question: {question} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFaceHub\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm = HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", model_kwargs={\"temperature\":0.8, \"max_length\":4096,\"max_new_tokens\":4096}),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(\n",
    "        search_type='similarity',\n",
    "        search_kwargs={ 'k': 4 },\n",
    "    ),\n",
    "    # return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt} #,\"verbose\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document './tmp/2024-02-15_12_48_07.docx' generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# q = \"what is the punishment for robbery ?\"\n",
    "q = \"who is judge ?\"\n",
    "q = \"one person has commited defamation, what should be punishment for it?\"\n",
    "# q = \"rioting has happened in neighbouring society. who will be responsible and what is the punishment for it\"\n",
    "# q = \"what is punishment for robbery and also murder ?\"\n",
    "# q = \"what are the rights of tenant and landlord ?\"\n",
    "# q = \"Liability of person for whose benefit riot is committed\"\n",
    "# q = \"person is selling adulterated drugs which is harmful to the health of people. person has also sold drug to the children below age of 15 what will be punishment for it?\"\n",
    "q=\"start with python programming language\"\n",
    "# q=\"explain all laws related to merriage\"\n",
    "# q+=\" and what is a household work?\"\n",
    "response = chain({\"query\":q, \"early_stopping\":True,\"min_length\":1000,\"max_tokens\":2000})\n",
    "\n",
    "from write_in_file import generate_docx_with_bullets\n",
    "generate_docx_with_bullets(heading=q,main_paragraph=response[\"result\"],output_folder=\"./tmp/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
